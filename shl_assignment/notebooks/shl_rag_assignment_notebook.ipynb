{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RtrP1WW4BBt"
   },
   "source": [
    "#1. Data Scraping Phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.shl.com/products/product-catalog/\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0 Safari/537.36\"\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_assessment_details(assessment):\n",
    "    url = assessment[\"url\"]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        if response.status_code != 200:\n",
    "            return assessment\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        description = \"N/A\"\n",
    "        duration = \"N/A\"\n",
    "\n",
    "        rows = soup.find_all(\n",
    "            \"div\",\n",
    "            class_=\"product-catalogue-training-calendar__row typ\"\n",
    "        )\n",
    "\n",
    "        for row in rows:\n",
    "            header = row.find(\"h4\")\n",
    "            if not header:\n",
    "                continue\n",
    "\n",
    "            title = header.get_text(strip=True).lower()\n",
    "\n",
    "            # ---- Description ----\n",
    "            if title == \"description\":\n",
    "                p = row.find(\"p\")\n",
    "                if p:\n",
    "                    description = p.get_text(\" \", strip=True)\n",
    "\n",
    "            # ---- Duration ----\n",
    "            if title == \"assessment length\":\n",
    "                p = row.find(\"p\")\n",
    "                if p:\n",
    "                    text = p.get_text(\" \", strip=True).lower()\n",
    "                    match = re.search(r\"=\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        duration = f\"{match.group(1)} minutes\"\n",
    "\n",
    "        assessment[\"description\"] = description\n",
    "        assessment[\"duration\"] = duration\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching {url}: {e}\")\n",
    "\n",
    "    return assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_table(table):\n",
    "    assessments = []\n",
    "    rows = table.find_all(\"tr\")[1:]  # skip header\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 4:\n",
    "            continue\n",
    "\n",
    "        # ---- Name & URL ----\n",
    "        name_tag = cols[0].find(\"a\")\n",
    "        name = name_tag.text.strip() if name_tag else \"Unknown\"\n",
    "        url = \"https://www.shl.com\" + name_tag[\"href\"] if name_tag else \"\"\n",
    "\n",
    "        # ---- Remote Testing ----\n",
    "        remote_testing = \"Yes\" if cols[1].find(\"span\", class_=\"catalogue__circle -yes\") else \"No\"\n",
    "\n",
    "        # ---- Adaptive / IRT ----\n",
    "        adaptive_irt = \"Yes\" if cols[2].find(\"span\", class_=\"catalogue__circle -yes\") else \"No\"\n",
    "\n",
    "        # ---- Test Type ----\n",
    "        test_keys = cols[3].find_all(\"span\", class_=\"product-catalogue__key\")\n",
    "        test_type = \", \".join(k.text.strip() for k in test_keys) if test_keys else \"N/A\"\n",
    "\n",
    "        assessments.append({\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"test_type\": test_type,\n",
    "            \"remote_testing\": remote_testing,\n",
    "            \"adaptive_irt\": adaptive_irt,\n",
    "            \"duration\": \"N/A\",\n",
    "            \"description\": \"N/A\"\n",
    "        })\n",
    "\n",
    "    return assessments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pages_for_type(type_param, max_pages, label):\n",
    "    all_assessments = []\n",
    "\n",
    "    for start in range(0, max_pages * 12, 12):\n",
    "        url = f\"{BASE_URL}?start={start}&type={type_param}\"\n",
    "        print(f\"[{label}] Scraping ‚Üí {url}\")\n",
    "\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"[{label}] ‚ùå Failed to fetch page\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find(\"table\")\n",
    "\n",
    "        if not table:\n",
    "            print(f\"[{label}] üö´ No table found. Stopping.\")\n",
    "            break\n",
    "\n",
    "        assessments = scrape_table(table)\n",
    "        if not assessments:\n",
    "            break\n",
    "\n",
    "        all_assessments.extend(assessments)\n",
    "        time.sleep(1)  # polite scraping\n",
    "\n",
    "    return all_assessments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_shl_catalog():\n",
    "    print(\"üîç Scraping Pre-packaged Job Solutions...\")\n",
    "    prepackaged = scrape_pages_for_type(type_param=2, max_pages=12, label=\"Pre-packaged\")\n",
    "\n",
    "    print(\"\\nüîç Scraping Individual Test Solutions...\")\n",
    "    individual = scrape_pages_for_type(type_param=1, max_pages=32, label=\"Individual\")\n",
    "\n",
    "    all_assessments = prepackaged + individual\n",
    "    print(f\"\\nüì¶ Total assessments found: {len(all_assessments)}\")\n",
    "\n",
    "    print(\"\\nüîç Fetching descriptions & durations...\")\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = [executor.submit(fetch_assessment_details, a) for a in all_assessments]\n",
    "\n",
    "        for i, future in enumerate(as_completed(futures), 1):\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Progress: {i}/{len(all_assessments)}\")\n",
    "\n",
    "    return pd.DataFrame(all_assessments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrape_shl_catalog()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"shl_assessments.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Saved {len(df)} records to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4FscVUY4f3z"
   },
   "source": [
    "#Clean the Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "input_path = list(uploaded.keys())[0]\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"name\", \"url\"]).reset_index(drop=True)\n",
    "\n",
    "def clean_test_type(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    parts = [p.strip() for p in str(x).split(\",\")]\n",
    "    return \",\".join(sorted(set(parts)))\n",
    "\n",
    "df[\"test_type\"] = df[\"test_type\"].apply(clean_test_type)\n",
    "\n",
    "binary_map = {\"Yes\": 1, \"No\": 0}\n",
    "df[\"remote_testing\"] = df[\"remote_testing\"].map(binary_map)\n",
    "df[\"adaptive_irt\"] = df[\"adaptive_irt\"].map(binary_map)\n",
    "\n",
    "def clean_duration(x):\n",
    "    if pd.isna(x) or x == \"N/A\":\n",
    "        return None\n",
    "    m = re.search(r\"\\d+\", str(x))\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "df[\"duration_minutes\"] = df[\"duration\"].apply(clean_duration)\n",
    "df.drop(columns=[\"duration\"], inplace=True)\n",
    "\n",
    "def clean_text(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    return re.sub(r\"\\s+\", \" \", str(x)).strip()\n",
    "\n",
    "df[\"description\"] = df[\"description\"].apply(clean_text)\n",
    "df[\"desc_length\"] = df[\"description\"].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "df = df.dropna(subset=[\"name\", \"url\", \"test_type\"])\n",
    "\n",
    "output_path = \"shl_assessments_clean.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"‚úÖ Cleaning completed\")\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Saved as:\", output_path)\n",
    "\n",
    "files.download(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a08PDW245gL"
   },
   "source": [
    "#2. Processed Phase(Build Embedding and Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "input_path = list(uploaded.keys())[0]\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "df = df.dropna(subset=[\"description\"]).reset_index(drop=True)\n",
    "\n",
    "texts = df[\"description\"].tolist()\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "np.save(\"shl_embeddings.npy\", embeddings)\n",
    "\n",
    "metadata = df.drop(columns=[\"description\"])\n",
    "metadata.to_csv(\"shl_metadata.csv\", index=False)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Files generated:\")\n",
    "print(\" - shl_embeddings.npy\")\n",
    "print(\" - shl_metadata.csv\")\n",
    "\n",
    "files.download(\"shl_embeddings.npy\")\n",
    "files.download(\"shl_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emb = np.load(\"shl_embeddings.npy\")\n",
    "print(emb.shape)\n",
    "print(np.linalg.norm(emb[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUacTNB35LZ9"
   },
   "source": [
    "# PHASE 3A ‚Äî RETRIEVAL EVALUATION (SLUG-BASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q faiss-cpu sentence-transformers openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google.colab import files\n",
    "import re\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "embeddings = np.load(\"shl_embeddings.npy\")\n",
    "metadata = pd.read_csv(\"shl_metadata.csv\")\n",
    "labels = pd.read_excel(\"Gen_AI Dataset (2).xlsx\")\n",
    "\n",
    "labels = labels.rename(columns={\n",
    "    \"Query\": \"query\",\n",
    "    \"Assessment_url\": \"url\"\n",
    "})\n",
    "\n",
    "def extract_slug(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    url = url.lower()\n",
    "    m = re.search(r\"/view/([^/]+)/?\", url)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "metadata[\"slug\"] = metadata[\"url\"].apply(extract_slug)\n",
    "labels[\"slug\"] = labels[\"url\"].apply(extract_slug)\n",
    "\n",
    "metadata = metadata.dropna(subset=[\"slug\"])\n",
    "labels = labels.dropna(subset=[\"slug\"])\n",
    "\n",
    "labels = labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = labels.iloc[:20]\n",
    "test_df = labels.iloc[20:]\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "def retrieve_slugs(query, k=5):\n",
    "    q_emb = model.encode([query], normalize_embeddings=True)\n",
    "    _, indices = index.search(q_emb, k)\n",
    "    return metadata.iloc[indices[0]][\"slug\"].tolist()\n",
    "\n",
    "def evaluate(df, k=5):\n",
    "    recall_hits = 0\n",
    "    mrr_total = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        retrieved = retrieve_slugs(row[\"query\"], k)\n",
    "        gt_slug = row[\"slug\"]\n",
    "\n",
    "        if gt_slug in retrieved:\n",
    "            recall_hits += 1\n",
    "            rank = retrieved.index(gt_slug) + 1\n",
    "            mrr_total += 1 / rank\n",
    "\n",
    "    return recall_hits / len(df), mrr_total / len(df)\n",
    "\n",
    "train_recall, train_mrr = evaluate(train_df)\n",
    "test_recall, test_mrr = evaluate(test_df)\n",
    "\n",
    "print(\"PHASE 3A ‚Äî RETRIEVAL EVALUATION (SLUG-BASED)\")\n",
    "print(\"==========================================\")\n",
    "print(f\"Train Queries: {len(train_df)}\")\n",
    "print(f\"Test Queries : {len(test_df)}\\n\")\n",
    "print(f\"Train Recall@5: {train_recall:.4f}\")\n",
    "print(f\"Train MRR     : {train_mrr:.4f}\\n\")\n",
    "print(f\"Test Recall@5 : {test_recall:.4f}\")\n",
    "print(f\"Test MRR      : {test_mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "labels = pd.read_excel(\"Gen_AI Dataset (2).xlsx\")\n",
    "metadata = pd.read_csv(\"shl_metadata.csv\")\n",
    "\n",
    "labels = labels.rename(columns={\n",
    "    \"Query\": \"query\",\n",
    "    \"Assessment_url\": \"url\"\n",
    "})\n",
    "\n",
    "print(\"Sample labeled URLs:\")\n",
    "print(labels[\"url\"].head(5).tolist())\n",
    "\n",
    "print(\"\\nSample metadata URLs:\")\n",
    "print(metadata[\"url\"].head(5).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HYsgDiw5aVp"
   },
   "source": [
    "#PHASE 3B ‚Äî LLM QUERY UNDERSTANDING + RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q faiss-cpu sentence-transformers transformers openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "embeddings = np.load(\"shl_embeddings.npy\")\n",
    "metadata = pd.read_csv(\"shl_metadata.csv\")\n",
    "labels = pd.read_excel(\"Gen_AI Dataset (2).xlsx\")\n",
    "\n",
    "labels = labels.rename(columns={\n",
    "    \"Query\": \"query\",\n",
    "    \"Assessment_url\": \"url\"\n",
    "})\n",
    "\n",
    "def extract_slug(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    m = re.search(r\"/view/([^/]+)/?\", url.lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "metadata[\"slug\"] = metadata[\"url\"].apply(extract_slug)\n",
    "labels[\"slug\"] = labels[\"url\"].apply(extract_slug)\n",
    "\n",
    "metadata = metadata.dropna(subset=[\"slug\"])\n",
    "labels = labels.dropna(subset=[\"slug\"])\n",
    "\n",
    "labels = labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = labels.iloc[:20]\n",
    "test_df = labels.iloc[20:]\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "rewriter = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "def rewrite_query(query):\n",
    "    prompt = (\n",
    "        \"You are an expert in talent assessment systems.\\n\"\n",
    "        \"Rewrite the following user query into a detailed assessment description \"\n",
    "        \"that would appear in a professional HR assessment catalog.\\n\\n\"\n",
    "        f\"Query: {query}\\n\\nRewritten description:\"\n",
    "    )\n",
    "    return rewriter(prompt, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "def retrieve_slugs(query, k=5):\n",
    "    rewritten = rewrite_query(query)\n",
    "    q_emb = embedder.encode([rewritten], normalize_embeddings=True)\n",
    "    _, indices = index.search(q_emb, k)\n",
    "    return metadata.iloc[indices[0]][\"slug\"].tolist()\n",
    "\n",
    "def evaluate(df, k=5):\n",
    "    recall_hits = 0\n",
    "    mrr_total = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        retrieved = retrieve_slugs(row[\"query\"], k)\n",
    "        if row[\"slug\"] in retrieved:\n",
    "            recall_hits += 1\n",
    "            rank = retrieved.index(row[\"slug\"]) + 1\n",
    "            mrr_total += 1 / rank\n",
    "\n",
    "    return recall_hits / len(df), mrr_total / len(df)\n",
    "\n",
    "train_recall, train_mrr = evaluate(train_df)\n",
    "test_recall, test_mrr = evaluate(test_df)\n",
    "\n",
    "print(\"PHASE 3B ‚Äî LLM QUERY UNDERSTANDING + RETRIEVAL\")\n",
    "print(\"==============================================\")\n",
    "print(f\"Train Queries: {len(train_df)}\")\n",
    "print(f\"Test Queries : {len(test_df)}\\n\")\n",
    "print(f\"Train Recall@5: {train_recall:.4f}\")\n",
    "print(f\"Train MRR     : {train_mrr:.4f}\\n\")\n",
    "print(f\"Test Recall@5 : {test_recall:.4f}\")\n",
    "print(f\"Test MRR      : {test_mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvrfG0S55gob"
   },
   "source": [
    "#PHASE 3C ‚Äî LLM RE-RANKING (FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q faiss-cpu sentence-transformers transformers openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "embeddings = np.load(\"shl_embeddings.npy\")\n",
    "metadata = pd.read_csv(\"shl_metadata.csv\")\n",
    "labels = pd.read_excel(\"Gen_AI Dataset (2).xlsx\")\n",
    "\n",
    "labels = labels.rename(columns={\n",
    "    \"Query\": \"query\",\n",
    "    \"Assessment_url\": \"url\"\n",
    "})\n",
    "\n",
    "def extract_slug(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    m = re.search(r\"/view/([^/]+)/?\", url.lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "metadata[\"slug\"] = metadata[\"url\"].apply(extract_slug)\n",
    "labels[\"slug\"] = labels[\"url\"].apply(extract_slug)\n",
    "\n",
    "metadata = metadata.dropna(subset=[\"slug\"])\n",
    "labels = labels.dropna(subset=[\"slug\"])\n",
    "\n",
    "labels = labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = labels.iloc[:20]\n",
    "test_df = labels.iloc[20:]\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "def retrieve_candidates(query, k=10):\n",
    "    q_emb = embedder.encode([query], normalize_embeddings=True)\n",
    "    _, indices = index.search(q_emb, k)\n",
    "    return metadata.iloc[indices[0]].reset_index(drop=True)\n",
    "\n",
    "def rerank(query, candidates):\n",
    "    prompt = \"You are an expert in talent assessment selection.\\n\"\n",
    "    prompt += f\"Query: {query}\\n\\nCandidates:\\n\"\n",
    "\n",
    "    for i, row in candidates.iterrows():\n",
    "        prompt += (\n",
    "            f\"{i+1}. Name: {row['name']}\\n\"\n",
    "            f\"   Test Types: {row['test_type']}\\n\"\n",
    "            f\"   Remote Testing: {row['remote_testing']}\\n\"\n",
    "            f\"   Adaptive IRT: {row['adaptive_irt']}\\n\"\n",
    "            f\"   Duration (minutes): {row.get('duration_minutes', 'N/A')}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt += \"Rank the candidates from most relevant to least relevant using indices only.\"\n",
    "\n",
    "    output = llm(prompt, do_sample=False)[0][\"generated_text\"]\n",
    "    indices = re.findall(r\"\\d+\", output)\n",
    "    indices = [int(i)-1 for i in indices if 0 <= int(i)-1 < len(candidates)]\n",
    "\n",
    "    return indices\n",
    "\n",
    "def evaluate(df, k=5):\n",
    "    recall_hits = 0\n",
    "    mrr_total = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        candidates = retrieve_candidates(row[\"query\"], k=10)\n",
    "        order = rerank(row[\"query\"], candidates)\n",
    "\n",
    "        if not order:\n",
    "            continue\n",
    "\n",
    "        ranked_slugs = candidates.iloc[order][\"slug\"].tolist()\n",
    "\n",
    "        if row[\"slug\"] in ranked_slugs[:k]:\n",
    "            recall_hits += 1\n",
    "            rank = ranked_slugs.index(row[\"slug\"]) + 1\n",
    "            mrr_total += 1 / rank\n",
    "\n",
    "    return recall_hits / len(df), mrr_total / len(df)\n",
    "\n",
    "train_recall, train_mrr = evaluate(train_df)\n",
    "test_recall, test_mrr = evaluate(test_df)\n",
    "\n",
    "print(\"PHASE 3C ‚Äî LLM RE-RANKING (FINAL)\")\n",
    "print(\"================================\")\n",
    "print(f\"Train Recall@5: {train_recall:.4f}\")\n",
    "print(f\"Train MRR     : {train_mrr:.4f}\\n\")\n",
    "print(f\"Test Recall@5 : {test_recall:.4f}\")\n",
    "print(f\"Test MRR      : {test_mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"shl_embeddings.npy\").astype(\"float32\")\n",
    "\n",
    "# Normalize embeddings BEFORE adding\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index size:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss_index.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "!pip install -q faiss-cpu sentence-transformers openpyxl\n",
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"SHL Assessment Recommendation API\",\n",
    "    version=\"1.0\"\n",
    ")\n",
    "\n",
    "print(\"Loading models and data...\")\n",
    "\n",
    "metadata = pd.read_csv(\"/content/shl_metadata.csv\")\n",
    "\n",
    "def extract_slug(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    m = re.search(r\"/view/([^/]+)/?\", url.lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "metadata[\"slug\"] = metadata[\"url\"].apply(extract_slug)\n",
    "metadata = metadata.dropna(subset=[\"slug\"]).reset_index(drop=True)\n",
    "\n",
    "faiss_index = faiss.read_index(\"/content/faiss_index.bin\")\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "print(\"Startup complete.\")\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def retrieve_candidates(query: str, k: int = 10) -> pd.DataFrame:\n",
    "    q_emb = embedder.encode([query], normalize_embeddings=True)\n",
    "    _, indices = faiss_index.search(q_emb, k)\n",
    "    return metadata.iloc[indices[0]].reset_index(drop=True)\n",
    "\n",
    "def rerank(query: str, candidates: pd.DataFrame):\n",
    "    prompt = \"You are an expert in talent assessment selection.\\n\"\n",
    "    prompt += f\"Query: {query}\\n\\nCandidates:\\n\"\n",
    "\n",
    "    for i, row in candidates.iterrows():\n",
    "        prompt += (\n",
    "            f\"{i+1}. Name: {row['name']}\\n\"\n",
    "            f\"   Test Types: {row['test_type']}\\n\"\n",
    "            f\"   Remote Testing: {row['remote_testing']}\\n\"\n",
    "            f\"   Adaptive IRT: {row['adaptive_irt']}\\n\"\n",
    "            f\"   Duration (minutes): {row.get('duration_minutes', 'N/A')}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt += \"Rank the candidates from most relevant to least relevant using indices only.\"\n",
    "\n",
    "    output = llm(prompt, do_sample=False)[0][\"generated_text\"]\n",
    "    indices = re.findall(r\"\\d+\", output)\n",
    "\n",
    "    ranked = []\n",
    "    for i in indices:\n",
    "        idx = int(i) - 1\n",
    "        if 0 <= idx < len(candidates) and idx not in ranked:\n",
    "            ranked.append(idx)\n",
    "\n",
    "    return ranked\n",
    "\n",
    "def recommend(query: str, top_k: int = 5):\n",
    "    candidates = retrieve_candidates(query, k=10)\n",
    "    order = rerank(query, candidates)\n",
    "\n",
    "    if not order:\n",
    "        candidates = candidates.head(top_k)\n",
    "    else:\n",
    "        candidates = candidates.iloc[order].head(top_k)\n",
    "\n",
    "    results = []\n",
    "    for _, row in candidates.iterrows():\n",
    "        results.append({\n",
    "            \"url\": row[\"url\"],\n",
    "            \"name\": row[\"name\"],\n",
    "            \"adaptive_support\": \"Yes\" if row[\"adaptive_irt\"] else \"No\",\n",
    "            \"description\": row.get(\"description\", \"\"),\n",
    "            \"duration\": int(row[\"duration_minutes\"]) if not pd.isna(row.get(\"duration_minutes\")) else None,\n",
    "            \"remote_support\": \"Yes\" if row[\"remote_testing\"] else \"No\",\n",
    "            \"test_type\": (\n",
    "                row[\"test_type\"].split(\",\")\n",
    "                if isinstance(row[\"test_type\"], str)\n",
    "                else []\n",
    "            )\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/recommend\")\n",
    "def recommend_endpoint(req: QueryRequest):\n",
    "    if not req.query or not req.query.strip():\n",
    "        raise HTTPException(status_code=400, detail=\"Query field is required\")\n",
    "\n",
    "    recommendations = recommend(req.query)\n",
    "\n",
    "    if not recommendations:\n",
    "        raise HTTPException(status_code=404, detail=\"No recommendations found\")\n",
    "\n",
    "    return {\n",
    "        \"recommended_assessments\": recommendations\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn\n",
    "!uvicorn app:app --host 0.0.0.0 --port 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
